{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdoulayegk/Zindi-Hackathons/blob/main/Layer_ai_Air_Quality_Prediction_Challenge_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Package to have access to the Zindi Platform features\n",
        "!pip -q install git+https://github.com/eaedk/testing-zindi-package.git"
      ],
      "metadata": {
        "id": "Nq2da4QC2pcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zindi.user import Zindian\n",
        "\n",
        "#@title Input Username\n",
        "\n",
        "# Login info for a Zindi Account\n",
        "\n",
        "USERNAME = \"Abdoulayegk\" #@param {type : \"string\"}\n",
        "\n",
        "# object\n",
        "user = Zindian(username=USERNAME) # Si"
      ],
      "metadata": {
        "id": "S0jYGvCF2pK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user.select_a_challenge(reward='all', kind='competition', active='true')"
      ],
      "metadata": {
        "id": "yX7PXz0c20Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user.download_dataset(destination=\"dataset\") # Download the dataset of the selected challenge"
      ],
      "metadata": {
        "id": "84iXSkeY2z8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost\n",
        "!pip install -q optuna\n"
      ],
      "metadata": {
        "id": "DurKIOC82z45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdr4_uIcnPDo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import missingno as mn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit, RepeatedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold, ShuffleSplit, TimeSeriesSplit,RepeatedKFold\n",
        "from xgboost import XGBRegressor \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from random import seed\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import RobustScaler, QuantileTransformer, PowerTransformer\n",
        "\n",
        "seed = 42\n",
        "seed = seed\n",
        "np.random.seed(seed)\n",
        "pd.set_option(\"display.max_columns\", 68)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_RY8cPRnUDU"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('dataset/train.csv').drop(['ID','device'],axis=1)\n",
        "test = pd.read_csv('dataset/test.csv').drop(['ID','device'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsW1sdVLnYBT"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynoUO94hnjCR"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vPy4xEsnruc"
      },
      "outputs": [],
      "source": [
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-PnVt8LnwBf"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7j4LifIrW-M"
      },
      "outputs": [],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPD3EQv9w3kT"
      },
      "source": [
        "I am going to look at the correlation between features I am going to do it base on the target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oURdMnS6uMVw"
      },
      "outputs": [],
      "source": [
        "train.corr()['pm2_5'].sample(60).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZbI_5-_uopM"
      },
      "outputs": [],
      "source": [
        "# Plot missing values in train set\n",
        "ax = train.isna().sum().sort_values().plot(kind = 'barh', figsize = (16, 13))\n",
        "plt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size':15})\n",
        "for p in ax.patches:\n",
        "    percentage ='{:,.0f}%'.format((p.get_width()/train.shape[0])*100)\n",
        "    width, height =p.get_width(),p.get_height()\n",
        "    x=p.get_x()+width+0.02\n",
        "    y=p.get_y()+height/2\n",
        "    ax.annotate(percentage,(x,y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuSaw7jg2g8f"
      },
      "outputs": [],
      "source": [
        "train.loc[:, 'site_latitude':'pm2_5'].describe().T.style.bar(subset=['mean'], color='#206ff2')\\\n",
        "                            .background_gradient(subset=['std'], cmap='Reds')\\\n",
        "                            .background_gradient(subset=['50%'], cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7luqDXCl2g8h"
      },
      "source": [
        "### Distrubition of the features on the training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAAw-zWA2g8j"
      },
      "outputs": [],
      "source": [
        "features = train.columns.values[3:13]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.distplot(train[feature], hist=False,label='train')\n",
        "    sns.distplot(test[feature], hist=False,label='test')\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiuyNUXg2g8m"
      },
      "outputs": [],
      "source": [
        "features = train.columns.values[13:23]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.distplot(train[feature], hist=False,label='train')\n",
        "    sns.distplot(test[feature], hist=False,label='test')\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7gTeWLb2g8o"
      },
      "outputs": [],
      "source": [
        "features = train.columns.values[23:33]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.distplot(train[feature], hist=False,label='train')\n",
        "    sns.distplot(test[feature], hist=False,label='test')\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vwKdraU2g8s"
      },
      "source": [
        "* we can see that most of the features are skewed either on the right or left so to solve this problem we will try to do the following:<br>\n",
        "    1. Log transformation of the features that are skewed <br>\n",
        "    2. Sqrt of the features that are skewed "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIWt8MXq2g8t"
      },
      "source": [
        "### Boxplot for different features to detect outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDiI4RXp2g8u"
      },
      "outputs": [],
      "source": [
        "eatures = train.columns.values[13:23]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.boxplot(train[feature])\n",
        "    sns.boxplot(test[feature])\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv7y1CF42g8v"
      },
      "outputs": [],
      "source": [
        "eatures = train.columns.values[13:23]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.boxplot(train[feature])\n",
        "    #sns.boxplot(test[feature])\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGbp8rau2g8y"
      },
      "outputs": [],
      "source": [
        "eatures = train.columns.values[13:23]\n",
        "i = 0\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
        "\n",
        "for feature in features:\n",
        "    i += 1\n",
        "    plt.subplot(5,2,i)\n",
        "    sns.boxplot(train[feature])\n",
        "    #sns.boxplot(test[feature])\n",
        "    plt.xlabel(feature, fontsize=9)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
        "    plt.tick_params(axis='y', which='major', labelsize=6)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oArsTzOO2g80"
      },
      "source": [
        "## Features engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yNG0-_t2g81"
      },
      "outputs": [],
      "source": [
        "# Extract day, month year and hour from the date column\n",
        "# day\n",
        "def converte_dates(df):\n",
        "    \n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    \n",
        "    #\n",
        "    df['date_day'] = df.date.dt.day\n",
        "\n",
        "    # month\n",
        "    df['date_month'] = df.date.dt.month\n",
        "\n",
        "    # year\n",
        "    df['date_year'] = df.date.dt.year\n",
        "\n",
        "    # hour\n",
        "    df['date_hour'] = df.date.dt.hour\n",
        "    \n",
        "    # minute\n",
        "    df['date_minute'] = df.date.dt.minute\n",
        "    \n",
        "    # day of week\n",
        "    df['date_dayofweek'] = df.date.dt.weekday\n",
        "    \n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "train = converte_dates(train).drop('date', axis=1)\n",
        "test = converte_dates(test).drop('date', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3bZzGrE2g82"
      },
      "source": [
        "Here I am capturing NaN per row and making new feature.\n",
        "I am doing this because sometime missing carry signal so we only give it to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lDLGRMx2g84"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(df):\n",
        "    df['NaN_row'] = df.isna().sum(axis=1)\n",
        "    df['std'] = df.std(axis=1)\n",
        "    return df\n",
        "\n",
        "train = feature_engineering(train)\n",
        "test = feature_engineering(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE5B19GO2g85"
      },
      "outputs": [],
      "source": [
        "### Log transform for some features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7_E28Sz2g85"
      },
      "outputs": [],
      "source": [
        "# Features selection\n",
        "\n",
        "X = train.drop('pm2_5',axis=1)\n",
        "y = train.pm2_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCcOBwdg2g-U"
      },
      "outputs": [],
      "source": [
        "X.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roOuCU5H2g-b"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('impute', IterativeImputer(random_state=seed)),\n",
        "    ('scale', RobustScaler())\n",
        "    #('quantiletransform', QuantileTransformer(random_state=seed))\n",
        "])\n",
        "\n",
        "X = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\n",
        "test = pd.DataFrame(columns=test.columns, data=pipeline.transform(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uzp_H2Nt2g-c"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_pred=[]\n",
        "oof_pred = []\n",
        "\n",
        "params = {'colsample_bytree': 0.384606276881856,\n",
        " 'learning_rate': 0.23251453473545997,\n",
        " 'max_depth': 7,\n",
        " 'subsample': 0.3530887571489526}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fold= KFold(n_splits=5)#15#5#10\n",
        "i=1\n",
        "for train_index, test_index in fold.split(X,y):     \n",
        "  \n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = np.log1p(y.iloc[train_index]), y.iloc[test_index]\n",
        "\n",
        "    model = LGBMRegressor(**params, objective = \"mae\")\n",
        "    model.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], early_stopping_rounds=300, verbose = False)#erly100\n",
        "\n",
        "    preds= model.predict(X_test)\n",
        "    print(\"err: \",(mean_absolute_error(y_test,np.expm1(preds))))  #Reverse transformation\n",
        "    oof_pred.append(mean_absolute_error(y_test,np.expm1(preds)))\n",
        "    p2 = model.predict(test[X.columns])\n",
        "    fold_pred.append(np.expm1(p2))\n",
        "    \n",
        "\n",
        "print(np.mean(oof_pred))"
      ],
      "metadata": {
        "id": "lpkkBAl_1t-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jSlmfVby2eoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j3Ft2_w2g-d"
      },
      "source": [
        "## Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aC1ACHc2g-f"
      },
      "outputs": [],
      "source": [
        "err1=[]\n",
        "y_pred_totcb1=[]\n",
        "\n",
        "fold=KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "for train_index, test_index in fold.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    m2 = CatBoostRegressor(task_type='GPU',loss_function='RMSE',)\n",
        "    m2.fit(X_train,y_train,eval_set=[(X_test, y_test)], verbose=0,)\n",
        "    preds = m2.predict(X_test)\n",
        "    print(\"err: \",np.sqrt(mean_squared_error(y_test,preds)))\n",
        "    err1.append(np.sqrt(mean_squared_error(y_test,preds)))\n",
        "    p2 = m2.predict(test)\n",
        "    y_pred_totcb1.append(p2)\n",
        "np.mean(err1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST0QU-RG2g-g"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhKhIuld2g-h"
      },
      "outputs": [],
      "source": [
        "# err1=[]\n",
        "# y_pred_totcb1=[]\n",
        "\n",
        "# fold=KFold(n_splits=10, random_state=seed,shuffle=True)\n",
        "# for train_index, test_index in fold.split(X, y):\n",
        "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "#     m2 = LGBMRegressor()\n",
        "#     m2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], verbose=100,)\n",
        "#     preds = m2.predict(X_test)\n",
        "#     print(\"err: \",np.sqrt(mean_squared_error(y_test,preds)))\n",
        "#     err1.append(np.sqrt(mean_squared_error(y_test,preds)))\n",
        "#     p2 = m2.predict(test)\n",
        "#     y_pred_totcb1.append(p2)\n",
        "# np.mean(err1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "_lzuvqZE2g-j"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1LSm3Vo2g-k"
      },
      "outputs": [],
      "source": [
        "# err1=[]\n",
        "# y_pred_totcb1=[]\n",
        "\n",
        "# fold=KFold(n_splits=10, random_state=seed,shuffle=True)\n",
        "# for train_index, test_index in fold.split(X, y):\n",
        "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "#     m2 = XGBRegressor()\n",
        "#     m2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_test, y_test)], verbose=100,)\n",
        "#     preds = m2.predict(X_test)\n",
        "#     print(\"err: \",np.sqrt(mean_squared_error(y_test,preds)))\n",
        "#     err1.append(np.sqrt(mean_squared_error(y_test,preds)))\n",
        "#     p2 = m2.predict(test)\n",
        "#     y_pred_totcb1.append(p2)\n",
        "# np.mean(err1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpXvqrI02g-l"
      },
      "outputs": [],
      "source": [
        "ss = pd.read_csv('dataset/SampleSubmission.csv')\n",
        "ss.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdxznTkX2g-n"
      },
      "outputs": [],
      "source": [
        "predic1 = np.mean(y_pred_totcb1, 0)\n",
        "a = {\"pm2_5\": predic1}\n",
        "predic1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giXfxMmh2g-o"
      },
      "outputs": [],
      "source": [
        "sub = {'ID':ss.ID,'pm2_5':predic1}\n",
        "s = pd.DataFrame(sub)\n",
        "s.to_csv('catboost.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXXUDOBT2g-o"
      },
      "outputs": [],
      "source": [
        "# # 0.7831404345536787\n",
        "feature_importance_df = pd.DataFrame(m2.feature_importances_, columns=['importance'])\n",
        "feature_importance_df['feature'] = X.columns\n",
        "\n",
        "plt.figure(figsize=(20, 12));\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by = ['importance'], ascending = False).head(60))\n",
        "plt.title('CatboostClassifier features importance (top 50):')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kXLyQvGo48XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Layer_ai_Air_Quality_Prediction_Challenge_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}